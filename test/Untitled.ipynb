{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "point1 = np.array([0,0,0])\n",
    "point2 = np.array([1,1,1])\n",
    "point3 = np.array([4,3,0])\n",
    "point4 = np.array([1,2,3])\n",
    "point5 = np.array([5,5,5])\n",
    "\n",
    "listofpoints1 = np.array([point1,point2,point3,point4,point5])\n",
    "\n",
    "print(listofpoints1)\n",
    "\n",
    "point21 = np.array([np.array([1,0,0])])\n",
    "\n",
    "print(point21)\n",
    "\n",
    "\n",
    "print(sp.spatial.distance.cdist(listofpoints1,point21,'sqeuclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import spatial\n",
    "\n",
    "#@np.vectorize\n",
    "def _computeSquareDistancesToClusters(clusters,point):\n",
    "    #clusters has to be a list of points!!!\n",
    "    temppoint=np.array([point])\n",
    "    print(\"----------------\")\n",
    "    print(temppoint)\n",
    "    print(clusters)\n",
    "    return sp.spatial.distance.cdist(clusters,temppoint,'sqeuclidean')\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------------------#\n",
    "    temp = np.zeros(len(clusters), dtype=np.float)\n",
    "    counter = 0\n",
    "    for x in clusters:\n",
    "        temp[counter] = np.linalg.norm(np.subtract(x,point))\n",
    "        counter +=1\n",
    "    return temp #np.min(np.array([(np.linalg.norm(np.subtract(x,point)) for x in clusters)]))\n",
    "\n",
    "def _initialization(traj,k):\n",
    "    distances = np.zeros(len(traj), dtype=np.float)\n",
    "    r = np.random.randint(0,len(traj))\n",
    "    # the r'th element is the first cluster center, chosen uniformly at random\n",
    "    clusters = np.array([traj[r]], dtype=np.float)\n",
    "    for l in range(1,k):\n",
    "        for i in range(len(traj)):\n",
    "            distances[i]=np.min(_computeSquareDistancesToClusters(clusters,traj[i]))\n",
    "        #choose next cluster point\n",
    "        nextClusterPoint = _chooseNextClusterPoint(distances)\n",
    "        clusters = np.concatenate([clusters,np.array([traj[nextClusterPoint]])])\n",
    "    return clusters\n",
    "\n",
    "def KMeans(data,dim=2,k=100):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data      : numpy ndarraylike, list of trajectories, all of the same length!!!\n",
    "    dim       : int, the dimension of the trajectories\n",
    "    k         : int, the number of clusters\n",
    "   \n",
    "    Return\n",
    "    ------\n",
    "    distrajs : numpy ndarraylike, list of discrete trajectories\n",
    "   \n",
    "    For each trajectory in the given data, do a kmeans(++) algorithm\n",
    "    to find the clusters and output discrete trajectories.\n",
    "    Therefore call a kmeans subprocedure.\n",
    "    \"\"\"\n",
    "    superData = np.concatenate(data)\n",
    "    \n",
    "    allClusters = _initialization(superData,k)\n",
    "    result = np.empty((len(data),len(data[0])))\n",
    "    while True:\n",
    "        allClustersOld = allClusters\n",
    "        helpme = np.zeros(len(superData))\n",
    "        for c in range(len(superData)):\n",
    "            helpme[c] = np.argmin(_computeSquareDistancesToClusters(allClusters,superData[c]))\n",
    "        countSize = np.zeros(k, dtype=np.int)\n",
    "        countMean = np.zeros((k,dim), dtype=np.float)\n",
    "        for c in range(len(superData)):\n",
    "            countSize[helpme[c]] += 1\n",
    "            countMean[helpme[c]] += superData[c]\n",
    "        for i in range(k):\n",
    "            allClusters[i] = np.multiply((1.0/countSize[i]) , countMean[i])\n",
    "        if np.max(allClusters - allClustersOld) < 0.1 and np.min(allClusters - allClustersOld) > -0.1:\n",
    "            break\n",
    "    \n",
    "    helpcounter = 0\n",
    "    for c1 in range(len(data)):\n",
    "        for c2 in range(len(data[c1])):\n",
    "            result[c1][c2] = helpme[helpcounter]\n",
    "            helpcounter += 1\n",
    "    return result\n",
    "        \n",
    "    \n",
    "\n",
    "def _chooseNextClusterPoint(distances):\n",
    "    #distances: list of floats (squared(!) distances)\n",
    "    #temp = np.array([d * d for d in distances])\n",
    "    total = np.sum(distances)\n",
    "    rand = np.random.uniform(0,total)\n",
    "    result = 0\n",
    "    while(rand >= 0):\n",
    "        rand -= distances[result]\n",
    "        if(rand < 0):\n",
    "            return result\n",
    "        result += 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mcmm\n",
    "\n",
    "import mcmm.example\n",
    "\n",
    "\n",
    "\n",
    "data = mcmm.example.generate_test_data(400,5)\n",
    "\n",
    "cluster = mcmm.clustering.cluster(data,20)\n",
    "\n",
    "print(cluster.centers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
